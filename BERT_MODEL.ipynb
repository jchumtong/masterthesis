{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb856c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn_crfsuite import CRF\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import ast \n",
    "import nltk\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import metrics\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForTokenClassification, TrainingArguments, Trainer\n",
    "from datasets import Dataset, ClassLabel, Sequence\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6180da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df615a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"transformers[torch]\" -U\n",
    "!pip install accelerate -U"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f5cb78",
   "metadata": {},
   "source": [
    "### Reading in Data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b1d7ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15662\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>venue_id</th>\n",
       "      <th>receipt_key</th>\n",
       "      <th>receipt_file</th>\n",
       "      <th>tokenized_receipt</th>\n",
       "      <th>preprocessed_receipt</th>\n",
       "      <th>parsed_receipt</th>\n",
       "      <th>bio_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5531</td>\n",
       "      <td>5531/01/0000000036812256/202003181643-u1584546...</td>\n",
       "      <td>*_*_*_*_*_*_*_*_*_*_*_*_*_*\\nThis receipt is p...</td>\n",
       "      <td>[[*_*_*_*_*_*_*_*_*_*_*_*_*_*], [This, receipt...</td>\n",
       "      <td>[[*_*_*_*_*_*_*_*_*_*_*_*_*_*]]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[O]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5531</td>\n",
       "      <td>5531/01/0000000036812256/202005150714-u1589519...</td>\n",
       "      <td>*_*_*_*_*_*_*_*_*_*_*_*_*_*\\nThis receipt is p...</td>\n",
       "      <td>[[*_*_*_*_*_*_*_*_*_*_*_*_*_*], [This, receipt...</td>\n",
       "      <td>[[*_*_*_*_*_*_*_*_*_*_*_*_*_*]]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[O]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5531</td>\n",
       "      <td>5531/01/0000000036812256/202005151410-u1589544...</td>\n",
       "      <td>*_*_*_*_*_*_*_*_*_*_*_*_*_*\\nThis receipt is p...</td>\n",
       "      <td>[[*_*_*_*_*_*_*_*_*_*_*_*_*_*], [This, receipt...</td>\n",
       "      <td>[[*_*_*_*_*_*_*_*_*_*_*_*_*_*]]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[O]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5531</td>\n",
       "      <td>5531/01/0000000036812256/202005152249-u1589575...</td>\n",
       "      <td>*_*_*_*_*_*_*_*_*_*_*_*_*_*\\nThis receipt is p...</td>\n",
       "      <td>[[*_*_*_*_*_*_*_*_*_*_*_*_*_*], [This, receipt...</td>\n",
       "      <td>[[*_*_*_*_*_*_*_*_*_*_*_*_*_*]]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[O]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5531</td>\n",
       "      <td>5531/01/0000000036812256/202005180927-u1589786...</td>\n",
       "      <td>*_*_*_*_*_*_*_*_*_*_*_*_*_*\\nThis receipt is p...</td>\n",
       "      <td>[[*_*_*_*_*_*_*_*_*_*_*_*_*_*], [This, receipt...</td>\n",
       "      <td>[[*_*_*_*_*_*_*_*_*_*_*_*_*_*]]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[O]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   venue_id                                        receipt_key  \\\n",
       "0      5531  5531/01/0000000036812256/202003181643-u1584546...   \n",
       "1      5531  5531/01/0000000036812256/202005150714-u1589519...   \n",
       "2      5531  5531/01/0000000036812256/202005151410-u1589544...   \n",
       "3      5531  5531/01/0000000036812256/202005152249-u1589575...   \n",
       "4      5531  5531/01/0000000036812256/202005180927-u1589786...   \n",
       "\n",
       "                                        receipt_file  \\\n",
       "0  *_*_*_*_*_*_*_*_*_*_*_*_*_*\\nThis receipt is p...   \n",
       "1  *_*_*_*_*_*_*_*_*_*_*_*_*_*\\nThis receipt is p...   \n",
       "2  *_*_*_*_*_*_*_*_*_*_*_*_*_*\\nThis receipt is p...   \n",
       "3  *_*_*_*_*_*_*_*_*_*_*_*_*_*\\nThis receipt is p...   \n",
       "4  *_*_*_*_*_*_*_*_*_*_*_*_*_*\\nThis receipt is p...   \n",
       "\n",
       "                                   tokenized_receipt  \\\n",
       "0  [[*_*_*_*_*_*_*_*_*_*_*_*_*_*], [This, receipt...   \n",
       "1  [[*_*_*_*_*_*_*_*_*_*_*_*_*_*], [This, receipt...   \n",
       "2  [[*_*_*_*_*_*_*_*_*_*_*_*_*_*], [This, receipt...   \n",
       "3  [[*_*_*_*_*_*_*_*_*_*_*_*_*_*], [This, receipt...   \n",
       "4  [[*_*_*_*_*_*_*_*_*_*_*_*_*_*], [This, receipt...   \n",
       "\n",
       "              preprocessed_receipt parsed_receipt bio_tags  \n",
       "0  [[*_*_*_*_*_*_*_*_*_*_*_*_*_*]]            NaN    [[O]]  \n",
       "1  [[*_*_*_*_*_*_*_*_*_*_*_*_*_*]]            NaN    [[O]]  \n",
       "2  [[*_*_*_*_*_*_*_*_*_*_*_*_*_*]]            NaN    [[O]]  \n",
       "3  [[*_*_*_*_*_*_*_*_*_*_*_*_*_*]]            NaN    [[O]]  \n",
       "4  [[*_*_*_*_*_*_*_*_*_*_*_*_*_*]]            NaN    [[O]]  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('final_df.csv')\n",
    "\n",
    "df['preprocessed_receipt'] = df['preprocessed_receipt'].apply(ast.literal_eval)\n",
    "df['bio_tags'] = df['bio_tags'].apply(ast.literal_eval)\n",
    "df['tokenized_receipt'] = df['tokenized_receipt'].apply(ast.literal_eval)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "641548f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>venue_id</th>\n",
       "      <th>receipt_key</th>\n",
       "      <th>receipt_file</th>\n",
       "      <th>tokenized_receipt</th>\n",
       "      <th>preprocessed_receipt</th>\n",
       "      <th>parsed_receipt</th>\n",
       "      <th>bio_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5531</td>\n",
       "      <td>5531/01/0000000036812256/202007161954-u1594922...</td>\n",
       "      <td>**start**                                 \\n--...</td>\n",
       "      <td>[[**start**], [--paid--], [Table:, 2], [------...</td>\n",
       "      <td>[[1, x, Thee, =&gt;, 2,20], [3, x, Jus, d'Orange,...</td>\n",
       "      <td>Thee x 1 order 220 Notes: _Jus d'Orange x 3 or...</td>\n",
       "      <td>[[B-QTY, O, B-UNIT, O, B-PRICE], [B-QTY, O, B-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5531</td>\n",
       "      <td>5531/01/0000000036812256/202007162054-u1594925...</td>\n",
       "      <td>**start**                                 \\n--...</td>\n",
       "      <td>[[**start**], [--paid--], [Table:, 7], [------...</td>\n",
       "      <td>[[2, x, Gregorius, =&gt;, 15,90], [2, x, Grimberg...</td>\n",
       "      <td>Gregorius x 2 order 1590 Notes: _Grimbergen Bl...</td>\n",
       "      <td>[[B-QTY, O, B-UNIT, O, B-PRICE], [B-QTY, O, B-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5531</td>\n",
       "      <td>5531/01/0000000036812256/202007162154-u1594929...</td>\n",
       "      <td>**start**                                 \\n--...</td>\n",
       "      <td>[[**start**], [--paid--], [Table:, 2], [------...</td>\n",
       "      <td>[[1, x, Lipton, Ice-Tea, =&gt;, 2,70], [2, x, Sou...</td>\n",
       "      <td>Lipton Ice-Tea x 1 order 270 Notes: _Sourcy Ro...</td>\n",
       "      <td>[[B-QTY, O, B-UNIT, I-UNIT, O, B-PRICE], [B-QT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5531</td>\n",
       "      <td>5531/01/0000000036812256/202007162254-u1594932...</td>\n",
       "      <td>**start**                                 \\n--...</td>\n",
       "      <td>[[**start**], [--paid--], [Table:, 7], [------...</td>\n",
       "      <td>[[6, x, Pico, de, Aneto, =&gt;, 25,50], [1, x, Ru...</td>\n",
       "      <td>Pico de Aneto x 6 order 2550 Notes: _Rundvlees...</td>\n",
       "      <td>[[B-QTY, O, B-UNIT, I-UNIT, I-UNIT, O, B-PRICE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5531</td>\n",
       "      <td>5531/01/0000000036812256/202007162254-u1594932...</td>\n",
       "      <td>**start**                                 \\n--...</td>\n",
       "      <td>[[**start**], [--paid--], [Table:, 2], [------...</td>\n",
       "      <td>[[1, x, Pinot, Grigio, Torre, Dei, V, =&gt;, 4,50...</td>\n",
       "      <td>Pinot Grigio Torre Dei V x 1 order 450 Notes: ...</td>\n",
       "      <td>[[B-QTY, O, B-UNIT, I-UNIT, I-UNIT, I-UNIT, I-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   venue_id                                        receipt_key  \\\n",
       "0      5531  5531/01/0000000036812256/202007161954-u1594922...   \n",
       "1      5531  5531/01/0000000036812256/202007162054-u1594925...   \n",
       "2      5531  5531/01/0000000036812256/202007162154-u1594929...   \n",
       "3      5531  5531/01/0000000036812256/202007162254-u1594932...   \n",
       "4      5531  5531/01/0000000036812256/202007162254-u1594932...   \n",
       "\n",
       "                                        receipt_file  \\\n",
       "0  **start**                                 \\n--...   \n",
       "1  **start**                                 \\n--...   \n",
       "2  **start**                                 \\n--...   \n",
       "3  **start**                                 \\n--...   \n",
       "4  **start**                                 \\n--...   \n",
       "\n",
       "                                   tokenized_receipt  \\\n",
       "0  [[**start**], [--paid--], [Table:, 2], [------...   \n",
       "1  [[**start**], [--paid--], [Table:, 7], [------...   \n",
       "2  [[**start**], [--paid--], [Table:, 2], [------...   \n",
       "3  [[**start**], [--paid--], [Table:, 7], [------...   \n",
       "4  [[**start**], [--paid--], [Table:, 2], [------...   \n",
       "\n",
       "                                preprocessed_receipt  \\\n",
       "0  [[1, x, Thee, =>, 2,20], [3, x, Jus, d'Orange,...   \n",
       "1  [[2, x, Gregorius, =>, 15,90], [2, x, Grimberg...   \n",
       "2  [[1, x, Lipton, Ice-Tea, =>, 2,70], [2, x, Sou...   \n",
       "3  [[6, x, Pico, de, Aneto, =>, 25,50], [1, x, Ru...   \n",
       "4  [[1, x, Pinot, Grigio, Torre, Dei, V, =>, 4,50...   \n",
       "\n",
       "                                      parsed_receipt  \\\n",
       "0  Thee x 1 order 220 Notes: _Jus d'Orange x 3 or...   \n",
       "1  Gregorius x 2 order 1590 Notes: _Grimbergen Bl...   \n",
       "2  Lipton Ice-Tea x 1 order 270 Notes: _Sourcy Ro...   \n",
       "3  Pico de Aneto x 6 order 2550 Notes: _Rundvlees...   \n",
       "4  Pinot Grigio Torre Dei V x 1 order 450 Notes: ...   \n",
       "\n",
       "                                            bio_tags  \n",
       "0  [[B-QTY, O, B-UNIT, O, B-PRICE], [B-QTY, O, B-...  \n",
       "1  [[B-QTY, O, B-UNIT, O, B-PRICE], [B-QTY, O, B-...  \n",
       "2  [[B-QTY, O, B-UNIT, I-UNIT, O, B-PRICE], [B-QT...  \n",
       "3  [[B-QTY, O, B-UNIT, I-UNIT, I-UNIT, O, B-PRICE...  \n",
       "4  [[B-QTY, O, B-UNIT, I-UNIT, I-UNIT, I-UNIT, I-...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "data = df\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a42b8178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['O'], ['O'], ['O', 'O'], ['O'], ['B-QTY', 'O', 'B-UNIT', 'O', 'B-PRICE'], ['B-QTY', 'O', 'B-UNIT', 'I-UNIT', 'O', 'B-PRICE'], ['B-QTY', 'O', 'B-UNIT', 'I-UNIT', 'O', 'B-PRICE'], ['B-QTY', 'O', 'B-UNIT', 'I-UNIT', 'I-UNIT', 'O', 'B-PRICE'], ['B-QTY', 'O', 'B-UNIT', 'I-UNIT', 'O', 'B-PRICE'], ['B-QTY', 'O', 'B-UNIT', 'O', 'B-PRICE'], ['B-QTY', 'O', 'B-UNIT', 'I-UNIT', 'I-UNIT', 'O', 'B-PRICE'], ['B-QTY', 'O', 'B-UNIT', 'I-UNIT', 'I-UNIT', 'O', 'B-PRICE'], ['B-QTY', 'O', 'B-UNIT', 'I-UNIT', 'O', 'B-PRICE'], ['B-QTY', 'O', 'B-UNIT', 'I-UNIT', 'I-UNIT', 'O', 'B-PRICE'], ['B-QTY', 'O', 'B-UNIT', 'I-UNIT', 'O', 'B-PRICE'], ['B-QTY', 'O', 'B-UNIT', 'I-UNIT', 'O', 'B-PRICE'], ['B-QTY', 'O', 'B-UNIT', 'I-UNIT', 'O', 'B-PRICE'], ['O'], ['O'], ['O'], ['O', 'O', 'O'], ['O'], ['O', 'O', 'O'], ['O', 'O', 'O'], ['O'], ['O', 'O'], ['O'], ['O']]\n",
      "[['**start**'], ['--paid--'], ['Table:', '2'], ['------------------------------------------'], ['1', 'x', 'Thee', '=>', '2,20'], ['3', 'x', 'Jus', \"d'Orange\", '=>', '8,10'], ['3', 'x', 'Glas', 'Rose', '=>', '12,75'], ['2', 'x', 'Pepsi', 'Cola', 'Max', '=>', '4,80'], ['2', 'x', 'Pepsi', 'Cola', '=>', '4,80'], ['2', 'x', '7-Up', '=>', '4,80'], ['5', 'x', 'Rioja', 'Crianza', 'Gailur', '=>', '28,75'], ['4', 'x', 'Pico', 'de', 'Aneto', '=>', '17,00'], ['2', 'x', 'Lipton', 'Ice-Tea', '=>', '5,40'], ['2', 'x', 'Colombard', '-', 'Sauvignon', '=>', '9,00'], ['1', 'x', 'Sourcy', 'Blauw', '=>', '2,20'], ['1', 'x', 'Div.', 'Keuken', '=>', '8,00'], ['1', 'x', 'Div.', 'Keuken', '=>', '8,00'], ['------------------------------------------'], ['115,80'], ['------------------------------------------'], ['PIN', '=>', '115,80'], ['------------------------------------------'], ['9%', '=>', '3,99'], ['21%', '=>', '11,71'], ['------------------------------------------'], ['16.07.2020', '19:51'], ['**end**'], ['V\\x01']]\n"
     ]
    }
   ],
   "source": [
    "def get_new_bio_tags(tokenized_receipt, preprocessed_receipt, bio_tags):\n",
    "    new_tags = []\n",
    "    preprocessed_receipt_tuples = [tuple(line) for line in preprocessed_receipt]\n",
    "    \n",
    "    tag_dict = dict(zip(preprocessed_receipt_tuples, bio_tags))\n",
    "    for line in tokenized_receipt:\n",
    "        line_tuple = tuple(line)\n",
    "        if line not in preprocessed_receipt:\n",
    "            line_length = len(line)\n",
    "            o_line = ['O'] * line_length\n",
    "            new_tags.append(o_line)\n",
    "        else:\n",
    "            new_tags.append(tag_dict[line_tuple])\n",
    "            \n",
    "    return new_tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06410c8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['**start**'],\n",
       " ['--paid--'],\n",
       " ['Table:', '1'],\n",
       " ['------------------------------------------'],\n",
       " ['2', 'x', 'Karmeliet', '=>', '11,00'],\n",
       " ['------------------------------------------'],\n",
       " ['11,00'],\n",
       " ['------------------------------------------'],\n",
       " ['Contant', '=>', '11,00'],\n",
       " ['------------------------------------------'],\n",
       " ['21%', '=>', '1,91'],\n",
       " ['------------------------------------------'],\n",
       " ['01.08.2020', '16:27'],\n",
       " ['**end**'],\n",
       " ['V\\x01']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['bio_tags'] = df.apply(lambda row: get_new_bio_tags(row['tokenized_receipt'], row['preprocessed_receipt'], row['bio_tags']), axis=1)\n",
    "df.loc[1234,'tokenized_receipt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02c82aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-QTY', 'O', 'B-UNIT', 'I-UNIT', 'I-UNIT', 'O', 'B-PRICE']\n"
     ]
    }
   ],
   "source": [
    "lines = [line for receipt in df['tokenized_receipt'] for line in receipt]\n",
    "tags = [tag for receipt in df['bio_tags'] for tag in receipt]\n",
    "print(tags[243])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf71578c",
   "metadata": {},
   "source": [
    "### Data Preprocessing ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e152bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_tokens = [token for receipt in df['tokenized_receipt'] for token in receipt]\n",
    "flattened_tags = [tag for tags in df['bio_tags'] for tag in tags]\n",
    "\n",
    "data = {\"tokens\": flattened_tokens, \"tags\": flattened_tags}\n",
    "dataset = Dataset.from_dict(data)\n",
    "\n",
    "tag_names = ['B-QTY', 'B-NOTE', 'I-UNIT', 'O', 'B-PRICE', 'B-UNIT', 'I-NOTE']\n",
    "tag2id = {tag: id for id, tag in enumerate(tag_names)}\n",
    "id2tag = {id: tag for tag, id in tag2id.items()}\n",
    "\n",
    "def encode_tags(tags):\n",
    "    return [tag2id[tag] for tag in tags]\n",
    "\n",
    "dataset = dataset.map(lambda x: {\"tags\": encode_tags(x[\"tags\"])})\n",
    "\n",
    "train_test_split = dataset.train_test_split(test_size=0.2)\n",
    "train_dataset = train_test_split[\"train\"]\n",
    "test_dataset = train_test_split[\"test\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf0ef51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizerFast\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(label[word_idx] if label[word_idx] != -100 else -100)\n",
    "            previous_word_idx = word_idx\n",
    "\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_and_align_labels, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_and_align_labels, batched=True)\n",
    "\n",
    "train_dataset = train_dataset.remove_columns([\"tokens\", \"tags\"])\n",
    "test_dataset = test_dataset.remove_columns([\"tokens\", \"tags\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61599b8f",
   "metadata": {},
   "source": [
    "### Model Training ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f956c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForTokenClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = BertForTokenClassification.from_pretrained('bert-base-uncased', num_labels=len(tag_names))\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fd238e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
